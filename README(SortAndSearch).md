#  Алгоритмы и структуры данных


---

##  Алгоритмы сортировки


---

## 1. Сортировка выбором (Selection Sort)

Определение:
Алгоритм последовательно находит наименьший элемент в неотсортированной части массива и перемещает его в начало.

Принцип работы:
1. Начинаем с первого элемента массива (`for i in range(n)`).
2. Находим минимальный элемент в неотсортированной части (`for j in range(i + 1, n), if arr[j] < arr[min_idx]`).
3. Меняем местами найденный минимальный элемент с текущим (`arr[i], arr[min_idx] = arr[min_idx], arr[i]`).
4. Увеличиваем отсортированную часть на один элемент (`i += 1`).
5. Повторяем процесс для оставшейся части массива.

Временная сложность:
- Лучший случай: O(n²) — даже если массив уже отсортирован, алгоритм всё равно ищет минимальный элемент на каждом шаге.
- Средний случай: O(n²) — два вложенных цикла, каждый размером ~n.
- Худший случай: O(n²) — при полностью обратной сортировке потребуется то же количество сравнений и перестановок.


Пример выполнения:
- Исходный массив: 64 25 12 22 11
- Процесс сортировки:
  - Шаг 1: 11 25 12 22 64
  - Шаг 2: 11 12 25 22 64
  - Шаг 3: 11 12 22 25 64
  - Шаг 4: 11 12 22 25 64
- Отсортированный массив: 11 12 22 25 64

---

## 2. Сортировка пузырьком (Bubble Sort)

Определение:
Метод многократно проходит через массив, сравнивая и переставляя соседние элементы.

Принцип работы:
1. Проходим по массиву несколько раз (`for i in range(n)`).
2. Сравниваем соседние элементы (`if arr[j] > arr[j + 1]`).
3. Если левый больше правого, меняем их местами (`arr[j], arr[j + 1] = arr[j + 1], arr[j]`).
4. После каждого прохода наибольший элемент “всплывает” в конец.
5. Повторяем до полной сортировки.

Временная сложность:
- Лучший случай: O(n) — один проход по уже отсортированному массиву без перестановок.
- Средний случай: O(n²) — два вложенных цикла при частично отсортированных данных.
- Худший случай: O(n²) — при обратной сортировке каждый элемент должен “всплыть” до конца.


Пример выполнения:
- Исходный массив: [64, 34, 25, 12, 22, 11, 90]
- Процесс сортировки:
  - Шаг 1: [34, 25, 12, 22, 11, 64, 90]
  - Шаг 2: [25, 12, 22, 11, 34, 64, 90]
  - Шаг 3: [12, 22, 11, 25, 34, 64, 90]
  - Шаг 4: [12, 11, 22, 25, 34, 64, 90]
  - Шаг 5: [11, 12, 22, 25, 34, 64, 90]
- Отсортированный массив: [11, 12, 22, 25, 34, 64, 90]

---

## 3. Сортировка вставками (Insertion Sort)

Определение:
Элементы по одному перемещаются в правильную позицию внутри уже отсортированной части массива.

Принцип работы:
1. Начинаем со второго элемента (`for i in range(1, len(arr))`).
2. Запоминаем текущий элемент (`key = arr[i]`).
3. Сдвигаем элементы, большие текущего, вправо (`while j >= 0 and arr[j] > key, arr[j + 1] = arr[j]`).
4. Вставляем элемент на найденную позицию (`arr[j + 1] = key`).
5. Повторяем для всех элементов.

Временная сложность:
- Лучший случай: O(n) — когда массив уже отсортирован, каждый элемент сразу находится на своём месте.
- Средний случай: O(n²) — элементы вставляются в разные позиции, требуется в среднем n/4 сдвигов.
- Худший случай: O(n²) — при обратной сортировке каждый элемент вставляется в начало.
  

Пример выполнения:
- Исходный массив: 12 11 13 5 6
- Процесс сортировки:
  - Шаг 1: 11 12 13 5 6
  - Шаг 2: 11 12 13 5 6
  - Шаг 3: 5 11 12 13 6
  - Шаг 4: 5 6 11 12 13
- Отсортированный массив: 5 6 11 12 13

---

## 4. Сортировка слиянием (Merge Sort)

Определение:
Рекурсивный алгоритм, разделяющий массив на мелкие части, сортирующий их и объединяющий обратно.

Принцип работы:
1. Разделяем массив пополам (`mid = len(arr) // 2`).
2. Рекурсивно сортируем левую и правую половины (`merge_sort(left), merge_sort(right)`).
3. Объединяем отсортированные половины (`while i < len(L) and j < len(R)`).
4.Сравниваем элементы из двух половин (`if L[i] <= R[j]`).
5. Добавляем оставшиеся элементы (`while i < len(L), while j < len(R)`).

Временная сложность:
- Лучший случай: O(n log n) — при любом входе массив делится пополам и объединяется одинаково быстро.
- Средний случай: O(n log n) — каждая рекурсия делит массив на две части.
- Худший случай: O(n log n) — даже при обратной сортировке выполняется одинаковое количество операций.



Пример выполнения:
- Исходный массив: 38 27 43 3 9 82 10
- Процесс сортировки:
  - Слияние: 27 38
  - Слияние: 3 43
  - Слияние: 3 27 38 43
  - Слияние: 9 82
  - Слияние: 9 10 82
  - Слияние: 3 9 10 27 38 43 82
- Отсортированный массив: 3 9 10 27 38 43 82

---

## 5. Сортировка Шелла (Shell Sort)

Определение:
Усовершенствованная версия сортировки вставками с использованием убывающих интервалов.

Принцип работы:
1. Выбираем начальный шаг (`gap = len(arr) // 2`).
2. Сортируем элементы на этом расстоянии методом вставок (`for i in range(gap, n)`).
3. Сравниваем и перемещаем элементы на расстоянии gap (`while j >= gap and arr[j - gap] > temp`).
4. Уменьшаем шаг и повторяем процесс (`gap //= 2`).
5. Завершаем сортировку с шагом 1 (обычная сортировка вставками).

Временная сложность:
- Лучший случай: O(n log n) — при удачном выборе интервалов и почти отсортированных данных.
- Средний случай: O(n log n) — обычно шаги сокращаются логарифмически.
- Худший случай: O(n²) — если интервалы выбраны неудачно или данные в обратном порядке.



Пример выполнения:
- Исходный массив: [12, 34, 54, 2, 3]
- Процесс сортировки:
  - Шаг 1, gap = 2:
    - i=2: [12, 34, 54, 2, 3]
    - i=3: [2, 34, 54, 12, 3]
    - i=4: [2, 3, 54, 12, 34]
  - Шаг 2, gap = 1:
    - i=1: [2, 3, 54, 12, 34]
    - i=2: [2, 3, 12, 54, 34]
    - i=3: [2, 3, 12, 34, 54]
- Отсортированный массив: [2, 3, 12, 34, 54]

---

## 6. Быстрая сортировка (Quick Sort)

Определение:
Эффективный алгоритм, использующий стратегию “разделяй и властвуй” с выбором опорного элемента.

Принцип работы:
1. Выбираем опорный элемент (`pivot = arr[high]`).
2. Делим массив на элементы меньше и больше опорного (`for j in range(low, high)`).
3. Размещаем опорный элемент в правильной позиции (`arr[i + 1], arr[high] = arr[high], arr[i + 1]`).
4. Рекурсивно применяем к обеим частям (`quick_sort(arr, low, pi - 1), quick_sort(arr, pi + 1, high)`).

Временная сложность:
- Лучший случай: O(n log n) — если опорный элемент делит массив на две равные части.
- Средний случай: O(n log n) — в среднем разделение близко к равному.
- Худший случай: O(n²) — если опорный элемент всегда минимальный или максимальный.


Пример выполнения:
- Исходный массив: [10, 7, 8, 9, 1, 5]
- Процесс сортировки:
  - Опорный элемент 5 на позиции 0: [10, 7, 8, 9, 1, 5]
  - Опорный элемент 1 на позиции 0: [1, 5]
  - Опорный элемент 9 на позиции 3: [7, 8, 9, 10]
  - Опорный элемент 8 на позиции 1: [7, 8]
- Отсортированный массив: [1, 5, 7, 8, 9, 10]

---

## 7. Пирамидальная сортировка (Heap Sort)

Определение:
Алгоритм, использующий структуру данных “двоичная куча” для сортировки.

Принцип работы:
1. Строим max-кучу из массива (`for i in range(n // 2 - 1, -1, -1), heapify(arr, n, i)`).
2. Корень кучи содержит максимальный элемент.
3. Меняем корень с последним элементом (`arr[i], arr[0] = arr[0], arr[i]`).
4. Восстанавливаем свойства кучи (`heapify(arr, i, 0)`).
5. Повторяем, пока куча не пуста.

Временная сложность:
- Лучший случай: O(n log n) — при частично отсортированных данных структура кучи сохраняется.
- Средний случай: O(n log n) — одинаковая для любых данных.
- Худший случай: O(n log n) — всегда выполняется одинаковое количество операций.



Пример выполнения:- Исходный массив: 12 11 13 5 6 7
- Процесс сортировки:
  - Построение кучи:
    - Куча из 2: 12 11 13 5 6 7
    - Куча из 1: 12 11 13 5 6 7
    - Куча из 0: 13 11 12 5 6 7
  - Извлечение элементов:
    - Шаг 1: 12 11 7 5 6 13
    - Шаг 2: 11 6 7 5 12 13
    - Шаг 3: 7 6 5 11 12 13
    - Шаг 4: 6 5 7 11 12 13
    - Шаг 5: 5 6 7 11 12 13
- Отсортированный массив: 5 6 7 11 12 13

---

## Сводная таблица алгоритмов сортировки


# Алгоритмы поиска

## 1. Линейный поиск (Linear Search)

Определение:
Простейший алгоритм поиска элемента в массиве, который последовательно проверяет каждый элемент до нахождения искомого или конца массива.

Принцип работы:
1. Начинаем с первого элемента массива (`for i in range(len(arr))`).
2. Сравниваем каждый элемент с искомым (`if arr[i] == target`).
3. Если найден — возвращаем индекс (`return i`).
4. Если дошли до конца — возвращаем -1 (`return -1`).

Временная сложность:
- Лучший случай: O(1) — элемент найден сразу на первой позиции.
- Средний случай: O(n) — элемент находится примерно в середине массива.
- Худший случай: O(n) — элемент отсутствует или находится в конце массива.



Пример выполнения:
- Исходный массив: [3, 5, 2, 7, 9, 1, 4]
- Ищем элемент: 7
- Процесс поиска: Проверяем элементы 3 → 5 → 2 → 7
- Результат: элемент найден на позиции 3.

---

## 2. Бинарный поиск (Binary Search)

Определение:
Эффективный алгоритм для поиска в отсортированных массивах.

Принцип работы:
1. Определяем левую и правую границы (`left, right = 0, len(arr) - 1`).
2. Находим средний элемент (`mid = (left + right) // 2`).
3. Сравниваем его с искомым (`if arr[mid] == target, elif arr[mid] < target`).
4. Сужаем диапазон поиска (`left = mid + 1, right = mid - 1`).
5. Повторяем, пока границы не сойдутся.

Временная сложность:
- Лучший случай: O(1) — элемент находится сразу в середине массива.
- Средний случай: O(log n) — каждый раз делим область поиска пополам.
- Худший случай: O(log n) — элемент на краю или отсутствует, всё равно делим область пополам на каждом шаге.


Пример выполнения:
- Исходный массив: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
- Ищем элемент: 7
- Процесс поиска:
  - left=0, right=9, mid=4 (arr[4]=9) → сужаем до left=0, right=3
  - mid=1 (arr[1]=3) → сужаем до left=2, right=3
  - mid=2 (arr[2]=5) → сужаем до left=3, right=3
  - mid=3 (arr[3]=7)
- Результат: элемент найден на позиции 3.

---

## 3. Интерполяционный поиск (Interpolation Search)

Определение:
Улучшенный бинарный поиск для равномерно распределённых данных.

Принцип работы:
1. Вычисляем предполагаемую позицию элемента:
   pos = low + ((target - arr[low]) * (high - low)) // (arr[high] - arr[low])
2. Сравниваем элемент в позиции с искомым (`if arr[pos] == target`).
3. Сужаем область поиска (`low = pos + 1, high = pos - 1`).
4. Повторяем, пока элемент не найден или границы не пересекутся.

Временная сложность:
- Лучший случай: O(1) — элемент найден сразу на рассчитанной позиции.
- Средний случай: O(log log n) — для равномерного распределения элементов.
- Худший случай: O(n) — если данные распределены неравномерно, позиция может сильно ошибаться.


Пример выполнения:
- Исходный массив: [10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47]
- Ищем элемент: 18
- Процесс поиска: low=0, high=14, pos=4 (arr[4]=18)
- Результат: элемент найден на позиции 4.

---

## 4. Поиск Фибоначчи (Fibonacci Search)

Определение:
Алгоритм использует числа Фибоначчи для определения точек разделения массива.

Принцип работы:
1. Находим число Фибоначчи ≥ длины массива:
   while fib < n: fib2, fib1, fib = fib1, fib, fib1 + fib
2. Определяем позиции для сравнения (`offset = -1, i = min(offset + fib2, n - 1)`).
3.Сравниваем элемент с искомым (`if arr[i] < target, elif arr[i] > target`).
4. Сдвигаем область поиска в зависимости от результата.
5. Повторяем, пока элемент найден или массив не исчерпан.

Временная сложность:
- Лучший случай: O(1) — элемент находится на первой проверке.
- Средний случай: O(log n) — деление массива по числам Фибоначчи аналогично бинарному поиску.
- Худший случай: O(log n) — последовательное деление массива через числа Фибоначчи.



Пример выполнения:
- Исходный массив: [10, 22, 35, 40, 45, 50, 80, 82, 85, 90, 100]
- Ищем элемент: 85
- Процесс поиска:
  - Генерация чисел Фибоначчи: F(0)=1, F(1)=1, F(2)=2, … F(7)=13
  - Начальный offset: -1
  - Проверяем позицию 4: arr[4]=45 → сдвиг вправо, offset=4
  - Проверяем позицию 7: arr[7]=82 → сдвиг вправо, offset=7
  - Проверяем позицию 8: arr[8]=85
- Результат: элемент найден на позиции 8.

---
